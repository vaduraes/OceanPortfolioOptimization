{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download----- 0.4%\n",
      "Download----- 0.7%\n",
      "Download----- 1.1%\n",
      "Download----- 1.5%\n",
      "Download----- 1.9%\n",
      "Download----- 2.2%\n",
      "Download----- 2.6%\n",
      "Download----- 3.0%\n",
      "Download----- 3.4%\n",
      "Download----- 3.7%\n",
      "Download----- 4.1%\n",
      "Download----- 4.5%\n",
      "Download----- 4.9%\n",
      "Download----- 5.2%\n",
      "Download----- 5.6%\n",
      "Download----- 6.0%\n",
      "Download----- 6.4%\n",
      "Download----- 6.7%\n",
      "Download----- 7.1%\n",
      "Download----- 7.5%\n",
      "Download----- 7.9%\n",
      "Download----- 8.2%\n",
      "Download----- 8.6%\n",
      "Download----- 9.0%\n",
      "Download----- 9.4%\n",
      "Download----- 9.7%\n",
      "Download----- 10.1%\n",
      "Download----- 10.5%\n",
      "Download----- 10.9%\n",
      "Download----- 11.2%\n",
      "Download----- 11.6%\n",
      "Download----- 12.0%\n",
      "Download----- 12.4%\n",
      "Download----- 12.7%\n",
      "Download----- 13.1%\n",
      "Download----- 13.5%\n",
      "Download----- 13.9%\n",
      "Download----- 14.2%\n",
      "Download----- 14.6%\n",
      "Download----- 15.0%\n",
      "Download----- 15.4%\n",
      "Download----- 15.7%\n",
      "Download----- 16.1%\n",
      "Download----- 16.5%\n",
      "Download----- 16.9%\n",
      "Download----- 17.2%\n",
      "Download----- 17.6%\n",
      "Download----- 18.0%\n",
      "Download----- 18.4%\n",
      "Download----- 18.7%\n",
      "Download----- 19.1%\n",
      "Download----- 19.5%\n",
      "Download----- 19.9%\n",
      "Download----- 20.2%\n",
      "Download----- 20.6%\n",
      "Download----- 21.0%\n",
      "Download----- 21.3%\n",
      "Download----- 21.7%\n",
      "Download----- 22.1%\n",
      "Download----- 22.5%\n",
      "Download----- 22.8%\n",
      "Download----- 23.2%\n",
      "Download----- 23.6%\n",
      "Download----- 24.0%\n",
      "Download----- 24.3%\n",
      "Download----- 24.7%\n",
      "Download----- 25.1%\n",
      "Download----- 25.5%\n",
      "Download----- 25.8%\n",
      "Download----- 26.2%\n",
      "Download----- 26.6%\n",
      "Download----- 27.0%\n",
      "Download----- 27.3%\n",
      "Download----- 27.7%\n",
      "Download----- 28.1%\n",
      "Download----- 28.5%\n",
      "Download----- 28.8%\n",
      "Download----- 29.2%\n",
      "Download----- 29.6%\n",
      "Download----- 30.0%\n",
      "Download----- 30.3%\n",
      "Download----- 30.7%\n",
      "Download----- 31.1%\n",
      "Download----- 31.5%\n",
      "Download----- 31.8%\n",
      "Download----- 32.2%\n",
      "Download----- 32.6%\n",
      "Download----- 33.0%\n",
      "Download----- 33.3%\n",
      "Download----- 33.7%\n",
      "Download----- 34.1%\n",
      "Download----- 34.5%\n",
      "Download----- 34.8%\n",
      "Download----- 35.2%\n",
      "Download----- 35.6%\n",
      "Download----- 36.0%\n",
      "Download----- 36.3%\n",
      "Download----- 36.7%\n",
      "Download----- 37.1%\n",
      "Download----- 37.5%\n",
      "Download----- 37.8%\n",
      "Download----- 38.2%\n",
      "Download----- 38.6%\n",
      "Download----- 39.0%\n",
      "Download----- 39.3%\n",
      "Download----- 39.7%\n",
      "Download----- 40.1%\n",
      "Download----- 40.4%\n",
      "Download----- 40.8%\n",
      "Download----- 41.2%\n",
      "Download----- 41.6%\n",
      "Download----- 41.9%\n",
      "Download----- 42.3%\n",
      "Download----- 42.7%\n",
      "Download----- 43.1%\n",
      "Download----- 43.4%\n",
      "Download----- 43.8%\n",
      "Download----- 44.2%\n",
      "Download----- 44.6%\n",
      "Download----- 44.9%\n",
      "Download----- 45.3%\n",
      "Download----- 45.7%\n",
      "Download----- 46.1%\n",
      "Download----- 46.4%\n",
      "Download----- 46.8%\n",
      "Download----- 47.2%\n",
      "Download----- 47.6%\n",
      "Download----- 47.9%\n",
      "Download----- 48.3%\n",
      "Download----- 48.7%\n",
      "Download----- 49.1%\n",
      "Download----- 49.4%\n",
      "Download----- 49.8%\n",
      "Download----- 50.2%\n",
      "Download----- 50.6%\n",
      "Download----- 50.9%\n",
      "Download----- 51.3%\n",
      "Download----- 51.7%\n",
      "Download----- 52.1%\n",
      "Download----- 52.4%\n",
      "Download----- 52.8%\n",
      "Download----- 53.2%\n",
      "Download----- 53.6%\n",
      "Download----- 53.9%\n",
      "Download----- 54.3%\n",
      "Download----- 54.7%\n",
      "Download----- 55.1%\n",
      "Download----- 55.4%\n",
      "Download----- 55.8%\n",
      "Download----- 56.2%\n",
      "Download----- 56.6%\n",
      "Download----- 56.9%\n",
      "Download----- 57.3%\n",
      "Download----- 57.7%\n",
      "Download----- 58.1%\n",
      "Download----- 58.4%\n",
      "Download----- 58.8%\n",
      "Download----- 59.2%\n",
      "Download----- 59.6%\n",
      "Download----- 59.9%\n",
      "Download----- 60.3%\n",
      "Download----- 60.7%\n",
      "Download----- 61.0%\n",
      "Download----- 61.4%\n",
      "Download----- 61.8%\n",
      "Download----- 62.2%\n",
      "Download----- 62.5%\n",
      "Download----- 62.9%\n",
      "Download----- 63.3%\n",
      "Download----- 63.7%\n",
      "Download----- 64.0%\n",
      "Download----- 64.4%\n",
      "Download----- 64.8%\n",
      "Download----- 65.2%\n",
      "Download----- 65.5%\n",
      "Download----- 65.9%\n",
      "Download----- 66.3%\n",
      "Download----- 66.7%\n",
      "Download----- 67.0%\n",
      "Download----- 67.4%\n",
      "Download----- 67.8%\n",
      "Download----- 68.2%\n",
      "Download----- 68.5%\n",
      "Download----- 68.9%\n",
      "Download----- 69.3%\n",
      "Download----- 69.7%\n",
      "Download----- 70.0%\n",
      "Download----- 70.4%\n",
      "Download----- 70.8%\n",
      "Download----- 71.2%\n",
      "Download----- 71.5%\n",
      "Download----- 71.9%\n",
      "Download----- 72.3%\n",
      "Download----- 72.7%\n",
      "Download----- 73.0%\n",
      "Download----- 73.4%\n",
      "Download----- 73.8%\n",
      "Download----- 74.2%\n",
      "Download----- 74.5%\n",
      "Download----- 74.9%\n",
      "Download----- 75.3%\n",
      "Download----- 75.7%\n",
      "Download----- 76.0%\n",
      "Download----- 76.4%\n",
      "Download----- 76.8%\n",
      "Download----- 77.2%\n",
      "Download----- 77.5%\n",
      "Download----- 77.9%\n",
      "Download----- 78.3%\n",
      "Download----- 78.7%\n",
      "Download----- 79.0%\n",
      "Download----- 79.4%\n",
      "Download----- 79.8%\n",
      "Download----- 80.1%\n",
      "Download----- 80.5%\n",
      "Download----- 80.9%\n",
      "Download----- 81.3%\n",
      "Download----- 81.6%\n",
      "Download----- 82.0%\n",
      "Download----- 82.4%\n",
      "Download----- 82.8%\n",
      "Download----- 83.1%\n",
      "Download----- 83.5%\n",
      "Download----- 83.9%\n",
      "Download----- 84.3%\n",
      "Download----- 84.6%\n",
      "Download----- 85.0%\n",
      "Download----- 85.4%\n",
      "Download----- 85.8%\n",
      "Download----- 86.1%\n",
      "Download----- 86.5%\n",
      "Download----- 86.9%\n",
      "Download----- 87.3%\n",
      "Download----- 87.6%\n",
      "Download----- 88.0%\n",
      "Download----- 88.4%\n",
      "Download----- 88.8%\n",
      "Download----- 89.1%\n",
      "Download----- 89.5%\n",
      "Download----- 89.9%\n",
      "Download----- 90.3%\n",
      "Download----- 90.6%\n",
      "Download----- 91.0%\n",
      "Download----- 91.4%\n",
      "Download----- 91.8%\n",
      "Download----- 92.1%\n",
      "Download----- 92.5%\n",
      "Download----- 92.9%\n",
      "Download----- 93.3%\n",
      "Download----- 93.6%\n",
      "Download----- 94.0%\n",
      "Download----- 94.4%\n",
      "Download----- 94.8%\n",
      "Download----- 95.1%\n",
      "Download----- 95.5%\n",
      "Download----- 95.9%\n",
      "Download----- 96.3%\n",
      "Download----- 96.6%\n",
      "Download----- 97.0%\n",
      "Download----- 97.4%\n",
      "Download----- 97.8%\n",
      "Download----- 98.1%\n",
      "Download----- 98.5%\n",
      "Download----- 98.9%\n",
      "Download----- 99.3%\n",
      "Download----- 99.6%\n",
      "Download----- 100.0%\n"
     ]
    }
   ],
   "source": [
    "#Download wind data from NREL\n",
    "import h5pyd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import time\n",
    "#run using geo_env\n",
    "#Using a new version of Depths.nc as the old one keep getting corrupted\n",
    "\n",
    "#Hourly Wind Data from NREL\n",
    "#Information available\n",
    "\n",
    "#winddirection_100m\n",
    "#winddirection_10m\n",
    "#winddirection_120m\n",
    "#winddirection_140m\n",
    "#winddirection_160m\n",
    "#winddirection_200m\n",
    "#winddirection_40m\n",
    "#winddirection_60m\n",
    "#winddirection_80m\n",
    "#windspeed_100m\n",
    "#windspeed_10m\n",
    "#windspeed_120m\n",
    "#windspeed_140m\n",
    "#windspeed_160m\n",
    "#windspeed_200m\n",
    "#windspeed_40m\n",
    "#windspeed_60m\n",
    "#windspeed_80m\n",
    "\n",
    "#Inputs\n",
    "LatNC=[33, 37] #Lower and upper bounds for Latitude  (NC region of interest)\n",
    "LonNC=[-81,-74]#Lower and upper bounds for Longitude (NC region of interest)\n",
    "Data_Name='windspeed_160m' #Name of file you want to get\n",
    "\n",
    "\n",
    "Depth_NETCDF = xr.open_dataset(\"./Depths.nc\")#File with bathymetry data\n",
    "NREL = h5pyd.File(\"/nrel/wtk-us.h5\", 'r') #Open conection with NREL server\n",
    "        \n",
    "#The original projection on NREL data is a modified Lambert Conic\n",
    "Coordinates=NREL[\"coordinates\"][:,:]#Coordinates in latitude longitude for each point y,x of the original data\n",
    " \n",
    "XY_NC=[]#coordinates we are interested in downloading\n",
    "\n",
    "\n",
    "#Get estimated depth in a given lat long\n",
    "def GetDepth(Lat,Long):\n",
    "    \n",
    "    I_lat=np.argmin(np.square(Depth_NETCDF.lat.data-Lat))\n",
    "    I_lon=np.argmin(np.square(Depth_NETCDF.lon.data-Long))\n",
    "    \n",
    "    depth=Depth_NETCDF.elevation.data[I_lat,I_lon]  \n",
    "    \n",
    "    return depth\n",
    "    \n",
    "\n",
    "#Get coordinates we are interested in downloading. \n",
    "#We group these coordinates such that we can decrease the total size of the file downloaded\n",
    "for y in range(Coordinates.shape[0]):\n",
    "    x_min=99999\n",
    "    x_max=-1\n",
    "    \n",
    "    for x in range(Coordinates.shape[1]):\n",
    "    \n",
    "        if Coordinates[y,x]['lat']>=LatNC[0] and Coordinates[y,x]['lat']<=LatNC[1]\\\n",
    "        and Coordinates[y,x]['lon']>=LonNC[0] and Coordinates[y,x]['lon']<=LonNC[1]\\\n",
    "        and GetDepth(Coordinates[y,x]['lat'],Coordinates[y,x]['lon'])<0\\\n",
    "        and GetDepth(Coordinates[y,x]['lat'],Coordinates[y,x]['lon'])>-200:\n",
    "            if x_min>x:\n",
    "                x_min=x\n",
    "            \n",
    "            if x_max<x:\n",
    "                x_max=x\n",
    "            \n",
    "    if x_max!=-1:\n",
    "        XY_NC.append([y,x_min,x_max])\n",
    "\n",
    "#Convert list to numpy array. This will facilitate future manipulation of this information\n",
    "XY_NC = np.asarray(XY_NC)\n",
    "\n",
    "\n",
    "#Downloading the data\n",
    "i=-1\n",
    "while i!=(len(XY_NC)-1):\n",
    "    error=0\n",
    "    i=i+1\n",
    "    try:\n",
    "        if i==0:\n",
    "            #Create initial windspeed matrix and concatenate future wind data (windspeedTemp) on this same matrix\n",
    "            windspeed=NREL[Data_Name][:,XY_NC[i,0],XY_NC[i,1]:XY_NC[i,2]+1]\n",
    "        \n",
    "        else:\n",
    "            windspeedTemp=NREL[Data_Name][:,XY_NC[i,0],XY_NC[i,1]:XY_NC[i,2]+1]\n",
    "            \n",
    "        \n",
    "        Lat=Coordinates['lat'][XY_NC[i,0],XY_NC[i,1]:XY_NC[i,2]+1]\n",
    "        Lat=np.reshape(Lat,(len(Lat),1))\n",
    "        \n",
    "        Long=Coordinates['lon'][XY_NC[i,0],XY_NC[i,1]:XY_NC[i,2]+1]\n",
    "        Long=np.reshape(Long,(len(Long),1))\n",
    "    \n",
    "    except:\n",
    "        error=1\n",
    "        i=i-1\n",
    "        print(\"Error in the NREL server, too many requests- Waiting access release\")\n",
    "        time.sleep(61*60)\n",
    "        NREL = h5pyd.File(\"/nrel/wtk-us.h5\", 'r') #Open conection with NREL server\n",
    "     \n",
    "       \n",
    "    if error==0:      \n",
    "        if i==0:\n",
    "            LatLong=np.concatenate((Lat,Long),axis=1)      \n",
    "        else:\n",
    "            LatLong=np.concatenate((LatLong,np.concatenate((Lat,Long),axis=1)),axis=0)\n",
    "            windspeed=np.concatenate((windspeed,windspeedTemp),axis=1)\n",
    "\n",
    "    print('Download----- %.1f%%'% ((i+1)/len(XY_NC)*100))\n",
    "    \n",
    "    \n",
    "ReadMe='\\\n",
    "windspeed: mÂ³\\s \\n\\\n",
    "LatLong: Latitude,Logitude data\\n\\\n",
    "1) The data is in hourly discretization starting at 1/1/2007 and going up to\\\n",
    "12/31/2013 23:00'\n",
    "\n",
    "np.savez('./'+ Data_Name +'.npz',ReadMe=ReadMe, windspeed=windspeed, LatLong=LatLong)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
